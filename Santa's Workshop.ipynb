{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numba import njit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import os\n",
    "import random\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "\n",
    "family_data_path = './input/family_data.csv'\n",
    "submission_path = './input/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(family_data_path)\n",
    "submission = pd.read_csv(submission_path, index_col='family_id', dtype=np.uint16)\n",
    "\n",
    "family_size_dict = data[['n_people']].to_dict()['n_people']\n",
    "\n",
    "cols = ['choice_{}'.format(i) for i in range(10)]\n",
    "choice_dict = data[cols].to_dict()\n",
    "\n",
    "N_DAYS = 100\n",
    "MAX_OCCUPANCY = 300\n",
    "MIN_OCCUPANCY = 125\n",
    "\n",
    "# from 100 to 1\n",
    "days = list(range(N_DAYS,0,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cost:\n",
    "    def __init__(self, family_data_path = family_data_path):\n",
    "        family = pd.read_csv(family_data_path)\n",
    "        family_size_dict = family[['n_people']].to_dict()['n_people']\n",
    "        \n",
    "        self.family_size = np.array(list(family_size_dict.values()))\n",
    "        self.penalties = self._penality_array(family_size_dict)\n",
    "        self.choice_array_num = self._choice_array_num(family)\n",
    "        self.days = list(range(100, 0, -1))\n",
    "        \n",
    "    def _penality_array(self, family_size_dict):\n",
    "        return np.array([\n",
    "                    [\n",
    "                        0,\n",
    "                        50,\n",
    "                        50 + 9 * n,\n",
    "                        100 + 9 * n,\n",
    "                        200 + 9 * n,\n",
    "                        200 + 18 * n,\n",
    "                        300 + 18 * n,\n",
    "                        300 + 36 * n,\n",
    "                        400 + 36 * n,\n",
    "                        500 + 36 * n + 199 * n,\n",
    "                        500 + 36 * n + 398 * n\n",
    "                    ]\n",
    "                    for n in range(max(family_size_dict.values())+1)\n",
    "                ])\n",
    "    \n",
    "    def _choice_array_num(self, family):\n",
    "        cols = ['choice_{}'.format(i) for i in range(10)]\n",
    "        choice_dict = family[cols].to_dict()\n",
    "        choice_dict_num = [{i:vv for i, vv in enumerate(di.values())} for di in choice_dict.values()]\n",
    "        largest_choice_key = max(max(x.keys()) for x in choice_dict_num)\n",
    "        return np.array([\n",
    "                [\n",
    "                    choice[n] if n in choice else -1 \n",
    "                    for n in range(largest_choice_key+1)\n",
    "                ] \n",
    "                for choice in choice_dict_num\n",
    "            ])\n",
    "    \n",
    "#     @njit\n",
    "    def calculate(self, prediction):\n",
    "        penalty = 0\n",
    "\n",
    "        # We'll use this to count the number of people scheduled each day\n",
    "        daily_occupancy = np.zeros((len(days)+1))\n",
    "        N = self.family_size.shape[0]\n",
    "\n",
    "        print(self.choice_array_num)\n",
    "        # Looping over each family; d is the day, n is size of that family, \n",
    "        # and choice is their top choices\n",
    "        for i in range(N):\n",
    "            # add the family member count to the daily occupancy\n",
    "            n = self.family_size[i]\n",
    "            d = prediction[i]\n",
    "            choice = self.choice_array_num[i]\n",
    "\n",
    "            daily_occupancy[d] += n\n",
    "\n",
    "            # Calculate the penalty for not getting top preference\n",
    "            penalty += self.penalties[n, self.choice_array_num[i][d]]\n",
    "\n",
    "        # for each date, check total occupancy\n",
    "        #  (using soft constraints instead of hard constraints)\n",
    "        relevant_occupancy = daily_occupancy[1:]\n",
    "        incorrect_occupancy = np.any(\n",
    "            (relevant_occupancy > MAX_OCCUPANCY) | \n",
    "            (relevant_occupancy < MIN_OCCUPANCY)\n",
    "        )\n",
    "\n",
    "        if incorrect_occupancy:\n",
    "            penalty += 100000000\n",
    "\n",
    "        # Calculate the accounting cost\n",
    "        # The first day (day 100) is treated special\n",
    "        init_occupancy = daily_occupancy[days[0]]\n",
    "        accounting_cost = (init_occupancy - 125.0) / 400.0 * init_occupancy**(0.5)\n",
    "        # using the max function because the soft constraints might allow occupancy to dip below 125\n",
    "        accounting_cost = max(0, accounting_cost)\n",
    "\n",
    "        # Loop over the rest of the days, keeping track of previous count\n",
    "        yesterday_count = init_occupancy\n",
    "        for day in self.days[1:]:\n",
    "            today_count = daily_occupancy[day]\n",
    "            diff = np.abs(today_count - yesterday_count)\n",
    "            accounting_cost += max(0, (today_count - 125.0) / 400.0 * today_count**(0.5 + diff / 50.0))\n",
    "            yesterday_count = today_count\n",
    "\n",
    "        penalty += accounting_cost\n",
    "\n",
    "        return penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Workshop:\n",
    "    def __init__(self):\n",
    "        self.family_sizes = []\n",
    "        self.family_choices = []\n",
    "        self.assigned_days = []\n",
    "        self.cost = Cost()\n",
    "        self.done = False\n",
    "            \n",
    "    def reset(self):\n",
    "        self._set_state()\n",
    "        self.done = False\n",
    "        return self._get_env_state()\n",
    "    \n",
    "    def step(self, family_index, day_choice_index):\n",
    "        reward = -self.cost.calculate(self.assigned_days)\n",
    "        self.assigned_days[family_index] = self.state[family_index, day_choice_index]\n",
    "        return self._get_env_state(), reward, self.done\n",
    "    \n",
    "    def get_submission(self):\n",
    "        submission = pd.read_csv(submission_path, index_col='family_id')\n",
    "        score = self.cost.calculate(self.assigned_days)\n",
    "        submission.to_csv('submission_{}.csv'.format(score))\n",
    "        print('Score = {}'.format(score))\n",
    "        \n",
    "    def _set_state(self):\n",
    "        family = pd.read_csv(family_data_path)\n",
    "        choice_cols = ['choice_{}'.format(i) for i in range(10)]\n",
    "        self.family_choices = np.array(family[choice_cols])\n",
    "        self.family_sizes = np.array(family['n_people'])\n",
    "        \n",
    "        submission = pd.read_csv(submission_path, index_col='family_id')\n",
    "        self.assigned_days = np.array(submission['assigned_day'])  \n",
    "        \n",
    "    def _get_env_state(self):\n",
    "        return (self.assigned_days, self.family_choices, self.family_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 82   5  12 ...  17  17  80]\n",
      " [ 33  11  27 ...  27  53  88]\n",
      " [ 52  26 100 ...  32  67  13]\n",
      " ...\n",
      " [ 75  47  82 ...  21  77  40]\n",
      " [ 28  61  33 ...   7  70  47]\n",
      " [ 38   4  54 ...  66  92  11]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 61 is out of bounds for axis 1 with size 11",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-001279df6a66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mworkshop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWorkshop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mworkshop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mworkshop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-89-7a4b1e15a6e8>\u001b[0m in \u001b[0;36mget_submission\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmission_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'family_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massigned_days\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission_{}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Score = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-88-c66a90078e51>\u001b[0m in \u001b[0;36mcalculate\u001b[0;34m(self, prediction)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;31m# Calculate the penalty for not getting top preference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mpenalty\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# for each date, check total occupancy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 61 is out of bounds for axis 1 with size 11"
     ]
    }
   ],
   "source": [
    "workshop = Workshop()\n",
    "workshop.reset()\n",
    "workshop.get_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,   50,   50,  100,  200,  200,  300,  300,  400,  500,  500],\n",
       "       [   0,   50,   59,  109,  209,  218,  318,  336,  436,  735,  934],\n",
       "       [   0,   50,   68,  118,  218,  236,  336,  372,  472,  970, 1368],\n",
       "       [   0,   50,   77,  127,  227,  254,  354,  408,  508, 1205, 1802],\n",
       "       [   0,   50,   86,  136,  236,  272,  372,  444,  544, 1440, 2236],\n",
       "       [   0,   50,   95,  145,  245,  290,  390,  480,  580, 1675, 2670],\n",
       "       [   0,   50,  104,  154,  254,  308,  408,  516,  616, 1910, 3104],\n",
       "       [   0,   50,  113,  163,  263,  326,  426,  552,  652, 2145, 3538],\n",
       "       [   0,   50,  122,  172,  272,  344,  444,  588,  688, 2380, 3972]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([\n",
    "                    [\n",
    "                        0,\n",
    "                        50,\n",
    "                        50 + 9 * n,\n",
    "                        100 + 9 * n,\n",
    "                        200 + 9 * n,\n",
    "                        200 + 18 * n,\n",
    "                        300 + 18 * n,\n",
    "                        300 + 36 * n,\n",
    "                        400 + 36 * n,\n",
    "                        500 + 36 * n + 199 * n,\n",
    "                        500 + 36 * n + 398 * n\n",
    "                    ]\n",
    "                    for n in range(max(family_size_dict.values())+1)\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: 82, 1: 33, 2: 52, 3: 12, 4: 10, 5: 64, 6: 76, 7: 75, 8: 28, 9: 38}]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "family = pd.read_csv(family_data_path)\n",
    "cols = ['choice_{}'.format(i) for i in range(10)]\n",
    "choice_dict = family[cols].to_dict()\n",
    "# print(choice_dict)\n",
    "\n",
    "[{{i:di[0] for i, vv in enumerate(di.values())} for i, di in enumerate(choice_dict.values())}]\n",
    "# for i in range(5000):\n",
    "#     choice_dict_num[i] = \n",
    "\n",
    "\n",
    "# choice_dict_num = [{vv:i for i, vv in enumerate(di.values())} for di in choice_dict.values()]\n",
    "# print(choice_dict_num)\n",
    "# largest_choice_key = max(max(x.keys()) for x in choice_dict_num)\n",
    "# choices = np.array([\n",
    "#         [\n",
    "#             choice[n] if n in choice else -1 \n",
    "#             for n in range(largest_choice_key+1)\n",
    "#         ] \n",
    "#         for choice in choice_dict_num\n",
    "#     ])\n",
    "# choices[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.99\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "        self.target_model = self._build_model()\n",
    "        self.update_target_model()\n",
    "\n",
    "    \"\"\"Huber loss for Q Learning\n",
    "    References: https://en.wikipedia.org/wiki/Huber_loss\n",
    "                https://www.tensorflow.org/api_docs/python/tf/losses/huber_loss\n",
    "    \"\"\"\n",
    "\n",
    "    def _huber_loss(self, y_true, y_pred, clip_delta=1.0):\n",
    "        error = y_true - y_pred\n",
    "        cond  = tf.abs(error) <= clip_delta\n",
    "\n",
    "        squared_loss = 0.5 * tf.square(error)\n",
    "        quadratic_loss = 0.5 * tf.square(clip_delta) + clip_delta * (tf.abs(error) - clip_delta)\n",
    "\n",
    "        return tf.mean(tf.where(cond, squared_loss, quadratic_loss))\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss=self._huber_loss,\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def update_target_model(self):\n",
    "        # copy weights from model to target_model\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])  # returns action\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = self.model.predict(state)\n",
    "            if done:\n",
    "                target[0][action] = reward\n",
    "            else:\n",
    "                # a = self.model.predict(next_state)[0]\n",
    "                t = self.target_model.predict(next_state)[0]\n",
    "                target[0][action] = reward + self.gamma * np.amax(t)\n",
    "                # target[0][action] = reward + self.gamma * t[np.argmax(a)]\n",
    "            self.model.fit(state, target, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = 500\n",
    "env = gym.make('CartPole-v1')\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "# agent.load(\"./save/cartpole-ddqn.h5\")\n",
    "done = False\n",
    "batch_size = 32\n",
    "\n",
    "for e in range(episodes):\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    for time in range(500):\n",
    "        # env.render()\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        reward = reward if not done else -10\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            agent.update_target_model()\n",
    "            print(\"episode: {}/{}, score: {}, e: {:.2}\"\n",
    "                  .format(e, EPISODES, time, agent.epsilon))\n",
    "            break\n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.replay(batch_size)\n",
    "    # if e % 10 == 0:\n",
    "    #     agent.save(\"./save/cartpole-ddqn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_size = np.array(list(family_size_dict.values()))\n",
    "days_array = np.array(days)\n",
    "\n",
    "penalties_array = \n",
    "\n",
    "choice_dict_num = [{vv:i for i, vv in enumerate(di.values())} for di in choice_dict.values()]\n",
    "largest_choice_key = max(max(x.keys()) for x in choice_dict_num)\n",
    "choice_array_num = np.array([\n",
    "    [\n",
    "        choice[n] if n in choice else - 1 \n",
    "        for n in range(largest_choice_key+1)\n",
    "    ] \n",
    "    for choice in choice_dict_num\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = submission['assigned_day'].values\n",
    "start_score = cost_function(best, penalties_array, family_size, days_array)\n",
    "\n",
    "# loop over each family\n",
    "for fam_id in tqdm(range(len(best))):\n",
    "    # loop over each family choice\n",
    "    for pick in range(10):\n",
    "        day = choice_dict[fam_id][f'choice_{pick}']\n",
    "        temp = new.copy()\n",
    "        temp[fam_id] = day # add in the new pick\n",
    "        if cost_function(temp, penalties_array, family_size, days_array) < start_score:\n",
    "            new = temp.copy()\n",
    "            start_score = cost_function(new, penalties_array, family_size, days_array)\n",
    "\n",
    "submission['assigned_day'] = new\n",
    "score = cost_function(new, penalties_array, family_size, days_array)\n",
    "submission.to_csv(f'submission_{score}.csv')\n",
    "print(f'Score: {score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
